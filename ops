{"author":{"id":"656dd67b0f9bdf8bc451c83ff8f36ef959de2c8b4781d218d9958f9e71ef0639"},"ops":[{"type":6,"author":{"id":"656dd67b0f9bdf8bc451c83ff8f36ef959de2c8b4781d218d9958f9e71ef0639"},"timestamp":1598984784,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdElzc3VlRWRpdDo0MjM1NTYxNTU="},"nonce":"aD94hrl2fWOLaAi+C6uA1jcUXA4=","target":"d63375c66fca0c1c900153c6866219a2ce599d45a1dde4aaba338f5ffd8361c6","message":"This test is best used in Words test. It calculates the average bit flip count in pair-wise hash comparisons, demonstrating the closeness to the strict avalanche criterion (50.0%).\n\nExample code:\n```\n\tconst int HashLen = 32;\n\tuint8_t Hash1[ HashLen ];\n\tuint8_t Hash2[ HashLen ];\n\tuint64_t bc = 0;\n\n\tfor( i = 0; i \u003c StringList.getItemCount() - 1; i++ )\n\t{\n\t\tprvhash42s_oneshot( (uint8_t*) VOXSTR( StringList[ i ]),\n\t\t\tStringList[ i ].getLength(), Hash1, HashLen );\n\n\t\tprvhash42s_oneshot( (uint8_t*) VOXSTR( StringList[ i + 1 ]),\n\t\t\tStringList[ i + 1 ].getLength(), Hash2, HashLen );\n\n\t\tbc += countDiffBits( Hash1, Hash2, HashLen );\n\t}\n\n\tprintf( \"Avalanche criterion: %.1f%%\\n\", 100.0 * bc /\n\t\t( StringList.getItemCount() - 1 ) / ( HashLen * 8 ));\n```\n\n```\ninline int countDiffBits( const uint8_t* const Hash1,\n\tconst uint8_t* const Hash2, const int HashLen )\n{\n\tint cc = 0;\n\tint m;\n\n\tfor( m = 0; m \u003c HashLen; m++ )\n\t{\n\t\tuint8_t v1 = Hash1[ m ];\n\t\tuint8_t v2 = Hash2[ m ];\n\t\tint j;\n\n\t\tfor( j = 0; j \u003c 8; j++ )\n\t\t{\n\t\t\tcc += ( v1 \u0026 1 ) ^ ( v2 \u0026 1 );\n\t\t\tv1 \u003e\u003e= 1;\n\t\t\tv2 \u003e\u003e= 1;\n\t\t}\n\t}\n\n\treturn( cc );\n}\n```","files":null},{"type":3,"author":{"id":"656dd67b0f9bdf8bc451c83ff8f36ef959de2c8b4781d218d9958f9e71ef0639"},"timestamp":1598320434,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDY3OTQ1NTY1NA==","github-url":"https://github.com/rurban/smhasher/issues/145#issuecomment-679455654"},"nonce":"Lgx2VLP/0GQQ9ywkYlXDSb+5qes=","message":"@rurban A note on usage of hashes for file digests: usually the disk and network IO will be much slower than a hash function, so practically a 6GB/s (48Gbit/s) hash function is plenty enough. I would focus on cryptographic proofs of hash functions: the Avalanche criterion is a part of the proof, as well as the \"bit frequency normalcy\" test I've proposed before. The `sparse long` test is good at catching broken hash functions: I did use it myself to catch bugs. For example, a hash function may pass the Words test, but it may fail the `sparse long` test easily. Most mul+xorshift hash functions are irreversible anyway.","files":null},{"type":3,"author":{"id":"656dd67b0f9bdf8bc451c83ff8f36ef959de2c8b4781d218d9958f9e71ef0639"},"timestamp":1610447693,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDc1ODU2NTAzOQ==","github-url":"https://github.com/rurban/smhasher/issues/145#issuecomment-758565039"},"nonce":"1TQJwSYp9B3QGkNRhC4bPhH8I9k=","message":"This test is probably not needed.","files":null},{"type":4,"author":{"id":"656dd67b0f9bdf8bc451c83ff8f36ef959de2c8b4781d218d9958f9e71ef0639"},"timestamp":1610447693,"metadata":{"github-id":"MDExOkNsb3NlZEV2ZW50NDE5NTE2NjY0Nw=="},"nonce":"LBUEisQm6D6ug5pP8WH/+RjpXBk=","status":2}]}