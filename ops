{"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"ops":[{"type":3,"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"timestamp":1573471514,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDU1MjQwNDg1MA==","github-url":"https://github.com/rurban/smhasher/issues/31#issuecomment-552404850"},"nonce":"+LQg1bhucgfe/AZn1SrzByWP3mI=","message":"It makes sense conceptually to have the init state generation and the actual run be separate. When people contribute their hashes, they follow the structure that SMHasher requires of them. If SMHasher doesn't appear to require or offer a separate init stage, they'll stick it in the body and be slower. I've seen this with out-of-tree hashes. I appreciate switching to this has got large edit distance.\n\nNot that my opinion matters, as the one not doing the work, but I do not at all agree about limiting bit lengths. It breaks at least one promising out-of-tree hash I've seen. Folding n\u003e32 bits into 32 is also essentially a free mixing stage, which would cover up seed generation issues. I don't recall the exact examples of this, but I can almost guarantee that doing this would make things pass on your fork that would fail on Yves'.\n\nFundamentally, your fork is the canonical one and people code to it. Specifically, its speed results are quoted when people come up with 'the fastest hash in the world' (tm). There are lots of issues with that that I won't go into in this ticket, but the one that specifically relates to this discussion is that any function that has large internal state and wants to initialize it with non-trivially small initial state has to move that into the measured body because of the size limitation.\n\nWhere Yves' fork makes changes, it is strictly a superset of yours. If we're going to unify them, those changes need to be back-ported whole imho. Unless and until they are, for the things I do, it'd still make way more sense for me personally to port new hashes from your fork to his and run them there.\n\nI realize this reads as heckling from the peanut gallery, and I do most sincerely apologize for that ;)","files":null},{"type":6,"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"timestamp":1573471829,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDMwNjk0NTcwNQ=="},"nonce":"kfAAWX8LP5G4Xjnxtc5KDaPIyUo=","target":"39720c9468b629bc54bbb0012dbe0be52b805ab1d31cac5be012619c5f1677d9","message":"It makes sense conceptually to have the init state generation and the actual run be separate. When people contribute their hashes, they follow the structure that SMHasher requires of them. If SMHasher doesn't appear to require or offer a separate init stage, they'll stick it in the body and be slower. I've seen this with out-of-tree hashes. I appreciate switching to this has got large edit distance.\n\nNot that my opinion matters, as the one not doing the work, but I do not at all agree about limiting bit lengths. It breaks at least one promising out-of-tree hash I've seen. Folding n\u003e32 bits into 32 is also essentially a free mixing stage, which would cover up seed generation issues. I don't recall the exact examples of this, but I can almost guarantee that doing this would make things pass on your fork that would fail on Yves'. It was my first experience of his fork in fact - I ran some stuff I was working on using your fork on his, it failed, and I sat there whimpering 'b..b..but it passes on rurban..'\n\nFundamentally, your fork is the canonical one and people code to it. Specifically, its speed results are quoted when people come up with 'the fastest hash in the world' (tm). There are lots of issues with that that I won't go into in this ticket, but the one that specifically relates to this discussion is that any function that has large internal state and wants to initialize it with non-trivially small initial state has to move that into the measured body because of the size limitation.\n\nWhere Yves' fork makes changes, it is strictly a superset of yours. If we're going to unify them, those changes need to be back-ported whole imho. Unless and until they are, for the things I do, it'd still make way more sense for me personally to port new hashes from your fork to his and run them there.\n\nI realize this reads as heckling from the peanut gallery, and I do most sincerely apologize for that ;)","files":null}]}