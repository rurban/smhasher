{"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"ops":[{"type":3,"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"timestamp":1532648643,"metadata":{"github-id":"MDEyOklzc3VlQ29tbWVudDQwODI2ODE5Ng==","github-url":"https://github.com/rurban/smhasher/issues/46#issuecomment-408268196"},"nonce":"PmKKDYwGPFhT+hnmJQo9XqGbUEE=","message":"I've tracked this down to #15 \n\nThe off-by-one error fix is correct, so that's a multiplier of x = (32/31). Well caught.\n\nI'm not at all sure about the rest of the PR. @vegorov1 is correct in that we want to measure things lexically between the opening and the closing RDTSC and don't want things re-ordered into or out of there. The PR doesn't do that, instructions from inside the measurement can be executed during the opening RDTSC and instructions following the closing RDTSC can be executed before it. This needs some lfences or CPUID or some other barriers.\n\nMoreover, I am not at all certain that I agree that we should be clobbering pipelining. Unless our intended use case for the hash functions is to run them on an in-order architecture, pipelining is important and useful - if we didn't care about it, we could just go through the machine code with op code handbook in hand and count the cycles. Forcing serial execution doesn't fix our measurements, it simply distorts them in another direction.\n\nCurrent master yields an average ~129 cycles/hash for falkhash, for example, but ~98 with this change backed out. This is purely because it's being penalized for the latency of instructions used in a way that would never happen in real code. The same applies to other hashes, like metro and the t1ha variant I tested, that are well-behaved wrt pipelining.\n\nI agree that the case where we allow full pipelining on successively called hash functions under test is a bit optimistic, but so is running successive trials with the same length key, which advantages hash functions whose performance depends on good branch prediction for example.\n\nFundamentally, I very much disagree with replacing an existing speed testing mode with one that drastically alters the conditions and isn't any more correct, but rather \"differently broken\". Adding it as an additional speed testing mode would be fine and indeed beneficial, but this sort of drive-by yanking out of continuity in comparability is counterproductive imho.","files":null},{"type":6,"author":{"id":"6eee5efae6ac4c22551887b8f66b9bbb345d45511a0675f837fab3c1b02acdca"},"timestamp":1532648833,"metadata":{"github-id":"MDE1OlVzZXJDb250ZW50RWRpdDExMjk4MjcyOQ=="},"nonce":"uyngdGA9A1jAMllpXV4ZxXVZ0Ho=","target":"2b7b8596dba2e4830dd86c2ea775bef1d3d675f39d462f1ddf0c10a59d0b1dac","message":"I've tracked this down to #15 \n\nThe off-by-one error fix is correct, so that's a multiplier of x = (32/31). Well caught.\n\nI'm not at all sure about the rest of the PR. @vegorov1 is correct in that we want to measure things lexically between the opening and the closing RDTSC and don't want things re-ordered into or out of there. The PR doesn't do that, instructions from inside the measurement can be executed during the opening RDTSC and instructions following the closing RDTSC can be executed before it. This needs some lfences or CPUID or some other barriers.\n\nMoreover, I am not at all certain that I agree that we should be clobbering pipelining. Unless our intended use case for the hash functions is to run them on an in-order architecture, pipelining is important and useful - if we didn't care about it, we could just go through the machine code with op code handbook in hand and count the cycles. Forcing serial execution doesn't fix our measurements, it simply distorts them in another direction.\n\nCurrent master yields an average ~129 cycles/hash for falkhash, for example, but ~98 with this change backed out. This is purely because it's being penalized for the latency of instructions used in a way that would never happen in real code. The same applies to other hashes, like metro and the t1ha variant I tested, that are well-behaved wrt pipelining.\n\nI agree that the case where we allow full pipelining on successively called hash functions under test is a bit optimistic, but so is running successive trials with the same length key, which advantages hash functions whose performance depends on good branch prediction for example.\n\nFundamentally, I very much disagree with replacing an existing speed testing mode with one that drastically alters the conditions and isn't any more correct, but rather \"differently broken\". Adding it as an additional speed testing mode would be fine and indeed beneficial, but this sort of drive-by yanking out of continuity in comparability over time is counterproductive imho.","files":null}]}